{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data exported.\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name, sr=16000, mono=True, res_type='kaiser_fast')\n",
    "    X = librosa.util.normalize(X)\n",
    "    #IS THE NORMALIZATION ABOVE CORRECT? OR NORMALIZE MFCCS INSTEAD OF FILE\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=14)\n",
    "    return mfccs\n",
    "\n",
    "#iterates over all the files within subdirectories and calls extract_feature\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            mfccs = extract_feature(fn)\n",
    "            if mfccs.shape == (14, 63): #IF I REVERT TO OLD PREPROCESS, HANGE ALL 63 TO 87\n",
    "                features.append(mfccs)\n",
    "                labels.append(fn.split('/')[2].split('-')[1])\n",
    "    new_labels = [] #we need the labels to be numbers, not letters.\n",
    "    for i in labels:\n",
    "        if i == 'w':\n",
    "            new_labels.append(0)\n",
    "        if i == 't':\n",
    "            new_labels.append(1)\n",
    "        if i == 's':\n",
    "            new_labels.append(2)\n",
    "    return np.array(features), np.array(new_labels, dtype = np.int)\n",
    "\n",
    "parent_dir = 'mdataset'\n",
    "train_sub_dirs = ['finaltrain']\n",
    "test_sub_dirs = ['finaltest']\n",
    "\n",
    "train_features, train_labels = parse_audio_files(parent_dir,train_sub_dirs)\n",
    "test_features, test_labels = parse_audio_files(parent_dir,test_sub_dirs)\n",
    "\n",
    "#Zip labels and mfccs together to randomize the order\n",
    "train_data = zip(train_features, train_labels)\n",
    "test_data = zip(test_features, test_labels)\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "#Reshape for encoding.\n",
    "X_train = np.array([x.reshape( (14, 63, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (14, 63, 1) ) for x in X_test])\n",
    "\n",
    "#One-Hot encoding for classes\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, 3))\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 3))\n",
    "\n",
    "#Save MFCCS to avoid recomputing them (costly)\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "print(\"data exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1673, 14, 45, 1)\n",
      "(697, 14, 45, 1)\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "\n",
    "#model.add(Dense(14, input_shape=(14, 63, 1)))\n",
    "#model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.05)) #prevent overfitting\n",
    "\n",
    "#model.add(Dense(14, input_shape=(14, 63, 1)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(14, input_shape=(14, 63, 1)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, input_shape=(14, 63, 1)))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.05)) #prevent overfitting\n",
    "\n",
    "model.add(Dense(14))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2175/2175 [==============================] - 3s 1ms/step - loss: 0.5908 - acc: 0.7605\n",
      "Epoch 2/2\n",
      "2175/2175 [==============================] - 1s 624us/step - loss: 0.3135 - acc: 0.8906\n",
      "905/905 [==============================] - 1s 927us/step\n",
      "('Test score:', 0.4992281621332327)\n",
      "('Test accuracy:', 0.8121546963301811)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.84       396\n",
      "          1       0.75      0.93      0.83       277\n",
      "          2       0.93      0.58      0.72       232\n",
      "\n",
      "avg / total       0.83      0.81      0.81       905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=2)\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
