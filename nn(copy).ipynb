{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract MFCCs from the audio using Librosa\n",
    "### The chunks of audio are normalized, turned to mono, and converted into 16kHz sample rate. Then 14 MFCCs are computed for frames at regular intervals for each chunk. 45 frames of non-silent audio are needed for each chunk. If there are less than 45, the chunk is just skipped.\n",
    "### The MFCCs order is randomized, and then turned into One Hot Encoding for the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data exported.\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name, sr=16000, mono=True, res_type='kaiser_fast')\n",
    "    X = librosa.util.normalize(X)\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=14)\n",
    "    return mfccs\n",
    "\n",
    "#iterates over all the files within subdirectories and calls extract_feature\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            mfccs = extract_feature(fn)\n",
    "            #print(mfccs.shape)\n",
    "            if mfccs.shape[1] >= 45:\n",
    "                mfccs = np.resize(mfccs,(14,45))\n",
    "                features.append(mfccs)\n",
    "                labels.append(fn.split('/')[2].split('-')[1])\n",
    "    new_labels = [] #we need the labels to be numbers, not letters.\n",
    "    for i in labels:\n",
    "        if i == 'w':\n",
    "            new_labels.append(0)\n",
    "        if i == 't':\n",
    "            new_labels.append(1)\n",
    "        if i == 's':\n",
    "            new_labels.append(2)\n",
    "    return np.array(features), np.array(new_labels, dtype = np.int)\n",
    "\n",
    "parent_dir = 'mdataset'\n",
    "train_sub_dirs = ['siltrain']\n",
    "test_sub_dirs = ['siltest']\n",
    "\n",
    "train_features, train_labels = parse_audio_files(parent_dir,train_sub_dirs)\n",
    "test_features, test_labels = parse_audio_files(parent_dir,test_sub_dirs)\n",
    "\n",
    "#Zip labels and mfccs together to randomize the order\n",
    "train_data = zip(train_features, train_labels)\n",
    "test_data = zip(test_features, test_labels)\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "#Reshape for encoding.\n",
    "X_train = np.array([x.reshape( (14, 45, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (14, 45, 1) ) for x in X_test])\n",
    "\n",
    "#One-Hot encoding for classes\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, 3))\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 3))\n",
    "\n",
    "#Save MFCCS to avoid recomputing them (costly)\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "print(\"data exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1673, 14, 45, 1)\n",
      "(697, 14, 45, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neural Network\n",
    "### A very simple architecture leads to satisfying results. 4 layers in total, the input layer with 5% dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(14, input_shape=(14, 45, 1)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.05)) #prevent overfitting\n",
    "\n",
    "model.add(Dense(14))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(14))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and running\n",
    "### We can vary the number of epochs and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1673/1673 [==============================] - 1s 805us/step - loss: 0.6265 - acc: 0.7436\n",
      "Epoch 2/20\n",
      "1673/1673 [==============================] - 1s 579us/step - loss: 0.4323 - acc: 0.8249\n",
      "Epoch 3/20\n",
      "1673/1673 [==============================] - 1s 595us/step - loss: 0.3600 - acc: 0.8607\n",
      "Epoch 4/20\n",
      "1673/1673 [==============================] - 1s 566us/step - loss: 0.3278 - acc: 0.8703\n",
      "Epoch 5/20\n",
      "1673/1673 [==============================] - 1s 554us/step - loss: 0.3170 - acc: 0.8763\n",
      "Epoch 6/20\n",
      "1673/1673 [==============================] - 1s 578us/step - loss: 0.2899 - acc: 0.8811\n",
      "Epoch 7/20\n",
      "1673/1673 [==============================] - 1s 567us/step - loss: 0.2517 - acc: 0.9032\n",
      "Epoch 8/20\n",
      "1673/1673 [==============================] - 1s 547us/step - loss: 0.2538 - acc: 0.8978\n",
      "Epoch 9/20\n",
      "1673/1673 [==============================] - 1s 591us/step - loss: 0.2144 - acc: 0.9217\n",
      "Epoch 10/20\n",
      "1673/1673 [==============================] - 1s 567us/step - loss: 0.2340 - acc: 0.9091\n",
      "Epoch 11/20\n",
      "1673/1673 [==============================] - 1s 595us/step - loss: 0.1698 - acc: 0.9360\n",
      "Epoch 12/20\n",
      "1673/1673 [==============================] - 1s 573us/step - loss: 0.1560 - acc: 0.9450\n",
      "Epoch 13/20\n",
      "1673/1673 [==============================] - 1s 564us/step - loss: 0.1503 - acc: 0.9468\n",
      "Epoch 14/20\n",
      "1673/1673 [==============================] - 1s 601us/step - loss: 0.1197 - acc: 0.9558\n",
      "Epoch 15/20\n",
      "1673/1673 [==============================] - 1s 561us/step - loss: 0.1181 - acc: 0.9558\n",
      "Epoch 16/20\n",
      "1673/1673 [==============================] - 1s 573us/step - loss: 0.0885 - acc: 0.9719\n",
      "Epoch 17/20\n",
      "1673/1673 [==============================] - 1s 572us/step - loss: 0.0733 - acc: 0.9815\n",
      "Epoch 18/20\n",
      "1673/1673 [==============================] - 1s 568us/step - loss: 0.0634 - acc: 0.9839\n",
      "Epoch 19/20\n",
      "1673/1673 [==============================] - 1s 591us/step - loss: 0.0547 - acc: 0.9851\n",
      "Epoch 20/20\n",
      "1673/1673 [==============================] - 1s 577us/step - loss: 0.0438 - acc: 0.9874\n",
      "697/697 [==============================] - 0s 366us/step\n",
      "('Test score:', 1.0272739882790718)\n",
      "('Test accuracy:', 0.7977044478892595)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78       232\n",
      "          1       0.75      0.94      0.84       275\n",
      "          2       0.96      0.61      0.75       190\n",
      "\n",
      "avg / total       0.82      0.80      0.79       697\n",
      "\n",
      "CPU times: user 41.7 s, sys: 5.9 s, total: 47.6 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=20) #5 epochs works pretty damn good, 10 more consistent?\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model, and additional testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('84_RSil_Model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.7190257e-01 4.2809615e-01 1.2795387e-06]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('84_RSil_Model.h5')\n",
    "\n",
    "single = np.reshape(X_test[2], (1, 14, 45, 1))\n",
    "\n",
    "#get_3rd_layer_output = K.function([model.layers[0].input],[model.layers[8].output])\n",
    "#layer_output = get_3rd_layer_output([single])[0]\n",
    "#print(layer_output)\n",
    "#The above does the same as these keras functions:\n",
    "\n",
    "print(model.predict(single))\n",
    "print(model.predict_classes(single))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
